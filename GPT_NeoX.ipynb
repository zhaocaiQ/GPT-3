{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT-NeoX.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMhIBvqIpUjRbgvFxvyYrxu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhaocaiQ/GPT-3/blob/main/GPT_NeoX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# gpt-neox 깃허브 클론 생성"
      ],
      "metadata": {
        "id": "TALiRjJxlsrN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AnWbDv4H5CN",
        "outputId": "79dfb386-3f42-4b4d-998b-00bda410560e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gpt-neox'...\n",
            "remote: Enumerating objects: 10367, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 10367 (delta 18), reused 22 (delta 7), pack-reused 10330\u001b[K\n",
            "Receiving objects: 100% (10367/10367), 60.88 MiB | 17.64 MiB/s, done.\n",
            "Resolving deltas: 100% (7216/7216), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/EleutherAI/gpt-neox.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Slim weights pretrained model 다운로드"
      ],
      "metadata": {
        "id": "eu-ABS-Ml4ei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --cut-dirs=5 -nH -r --no-parent --reject \"index.html*\" https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/ -P 20B_checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zeeo6kKM5Lc",
        "outputId": "dccf52ad-b6c2-4b14-e457-e392f4794330"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-28 05:16:10--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/\n",
            "Resolving the-eye.eu (the-eye.eu)... 162.213.130.6\n",
            "Connecting to the-eye.eu (the-eye.eu)|162.213.130.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘20B_checkpoints/index.html.tmp’\n",
            "\n",
            "index.html.tmp          [ <=>                ]     659  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 05:16:11 (64.3 MB/s) - ‘20B_checkpoints/index.html.tmp’ saved [659]\n",
            "\n",
            "Loading robots.txt; please ignore errors.\n",
            "--2022-07-28 05:16:11--  https://the-eye.eu/robots.txt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2022-07-28 05:16:11 ERROR 404: Not Found.\n",
            "\n",
            "Removing 20B_checkpoints/index.html.tmp since it should be rejected.\n",
            "\n",
            "--2022-07-28 05:16:11--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/configs/\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘20B_checkpoints/configs/index.html.tmp’\n",
            "\n",
            "configs/index.html.     [ <=>                ]     353  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 05:16:11 (38.9 MB/s) - ‘20B_checkpoints/configs/index.html.tmp’ saved [353]\n",
            "\n",
            "Removing 20B_checkpoints/configs/index.html.tmp since it should be rejected.\n",
            "\n",
            "--2022-07-28 05:16:11--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/index.html.tmp’\n",
            "\n",
            "global_step150000/i     [ <=>                ]  12.76K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 05:16:11 (293 MB/s) - ‘20B_checkpoints/global_step150000/index.html.tmp’ saved [13069]\n",
            "\n",
            "Removing 20B_checkpoints/global_step150000/index.html.tmp since it should be rejected.\n",
            "\n",
            "--2022-07-28 05:16:11--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/20B_tokenizer.json\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2467981 (2.4M) [application/json]\n",
            "Saving to: ‘20B_checkpoints/20B_tokenizer.json’\n",
            "\n",
            "20B_tokenizer.json  100%[===================>]   2.35M  1.54MB/s    in 1.5s    \n",
            "\n",
            "2022-07-28 05:16:13 (1.54 MB/s) - ‘20B_checkpoints/20B_tokenizer.json’ saved [2467981/2467981]\n",
            "\n",
            "--2022-07-28 05:16:13--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/latest\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18 [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/latest’\n",
            "\n",
            "latest              100%[===================>]      18  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 05:16:13 (3.87 MB/s) - ‘20B_checkpoints/latest’ saved [18/18]\n",
            "\n",
            "--2022-07-28 05:16:13--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/configs/20B.yml\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6490 (6.3K) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/configs/20B.yml’\n",
            "\n",
            "configs/20B.yml     100%[===================>]   6.34K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 05:16:14 (1016 MB/s) - ‘20B_checkpoints/configs/20B.yml’ saved [6490/6490]\n",
            "\n",
            "--2022-07-28 05:16:14--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_00-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 309854955 (296M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_00-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 295.50M  11.3MB/s    in 23s     \n",
            "\n",
            "2022-07-28 05:16:37 (12.7 MB/s) - ‘20B_checkpoints/global_step150000/layer_00-model_00-model_states.pt’ saved [309854955/309854955]\n",
            "\n",
            "--2022-07-28 05:16:37--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_00-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 309854955 (296M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_00-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 295.50M  13.7MB/s    in 23s     \n",
            "\n",
            "2022-07-28 05:17:01 (12.7 MB/s) - ‘20B_checkpoints/global_step150000/layer_00-model_01-model_states.pt’ saved [309854955/309854955]\n",
            "\n",
            "--2022-07-28 05:17:01--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_02-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_02-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  8.44MB/s    in 43s     \n",
            "\n",
            "2022-07-28 05:17:44 (10.1 MB/s) - ‘20B_checkpoints/global_step150000/layer_02-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:17:44--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_02-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_02-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.4MB/s    in 33s     \n",
            "\n",
            "2022-07-28 05:18:17 (13.0 MB/s) - ‘20B_checkpoints/global_step150000/layer_02-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:18:17--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_03-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_03-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.7MB/s    in 33s     \n",
            "\n",
            "2022-07-28 05:18:51 (12.9 MB/s) - ‘20B_checkpoints/global_step150000/layer_03-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:18:51--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_03-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_03-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  8.53MB/s    in 48s     \n",
            "\n",
            "2022-07-28 05:19:39 (9.09 MB/s) - ‘20B_checkpoints/global_step150000/layer_03-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:19:39--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_04-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_04-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  9.86MB/s    in 51s     \n",
            "\n",
            "2022-07-28 05:20:31 (8.39 MB/s) - ‘20B_checkpoints/global_step150000/layer_04-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:20:31--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_04-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_04-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  11.8MB/s    in 37s     \n",
            "\n",
            "2022-07-28 05:21:08 (11.7 MB/s) - ‘20B_checkpoints/global_step150000/layer_04-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:21:08--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_05-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_05-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.5MB/s    in 34s     \n",
            "\n",
            "2022-07-28 05:21:43 (12.6 MB/s) - ‘20B_checkpoints/global_step150000/layer_05-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:21:43--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_05-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_05-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.3MB/s    in 40s     \n",
            "\n",
            "2022-07-28 05:22:23 (10.8 MB/s) - ‘20B_checkpoints/global_step150000/layer_05-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:22:23--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_06-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_06-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  11.1MB/s    in 37s     \n",
            "\n",
            "2022-07-28 05:23:00 (11.7 MB/s) - ‘20B_checkpoints/global_step150000/layer_06-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:23:00--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_06-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_06-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  12.0MB/s    in 33s     \n",
            "\n",
            "2022-07-28 05:23:34 (13.0 MB/s) - ‘20B_checkpoints/global_step150000/layer_06-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:23:34--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_07-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_07-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  12.9MB/s    in 35s     \n",
            "\n",
            "2022-07-28 05:24:09 (12.5 MB/s) - ‘20B_checkpoints/global_step150000/layer_07-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:24:09--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_07-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_07-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.3MB/s    in 38s     \n",
            "\n",
            "2022-07-28 05:24:48 (11.3 MB/s) - ‘20B_checkpoints/global_step150000/layer_07-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:24:48--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_08-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_08-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  11.4MB/s    in 36s     \n",
            "\n",
            "2022-07-28 05:25:24 (12.0 MB/s) - ‘20B_checkpoints/global_step150000/layer_08-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:25:24--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_08-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_08-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  12.2MB/s    in 37s     \n",
            "\n",
            "2022-07-28 05:26:02 (11.5 MB/s) - ‘20B_checkpoints/global_step150000/layer_08-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:26:02--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_09-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_09-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.4MB/s    in 33s     \n",
            "\n",
            "2022-07-28 05:26:35 (13.3 MB/s) - ‘20B_checkpoints/global_step150000/layer_09-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:26:35--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_09-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_09-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.7MB/s    in 33s     \n",
            "\n",
            "2022-07-28 05:27:08 (13.2 MB/s) - ‘20B_checkpoints/global_step150000/layer_09-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:27:08--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_10-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_10-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  11.9MB/s    in 36s     \n",
            "\n",
            "2022-07-28 05:27:44 (12.2 MB/s) - ‘20B_checkpoints/global_step150000/layer_10-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:27:44--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_10-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_10-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  10.9MB/s    in 45s     \n",
            "\n",
            "2022-07-28 05:28:30 (9.60 MB/s) - ‘20B_checkpoints/global_step150000/layer_10-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:28:30--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_11-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_11-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  9.00MB/s    in 46s     \n",
            "\n",
            "2022-07-28 05:29:16 (9.47 MB/s) - ‘20B_checkpoints/global_step150000/layer_11-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:29:16--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_11-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_11-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  9.06MB/s    in 79s     \n",
            "\n",
            "2022-07-28 05:30:36 (5.49 MB/s) - ‘20B_checkpoints/global_step150000/layer_11-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:30:36--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_12-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_12-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  4.25MB/s    in 86s     \n",
            "\n",
            "2022-07-28 05:32:04 (5.04 MB/s) - ‘20B_checkpoints/global_step150000/layer_12-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:32:04--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_12-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_12-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  6.02MB/s    in 70s     \n",
            "\n",
            "2022-07-28 05:33:14 (6.21 MB/s) - ‘20B_checkpoints/global_step150000/layer_12-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:33:14--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_13-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_13-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  10.0MB/s    in 54s     \n",
            "\n",
            "2022-07-28 05:34:09 (7.94 MB/s) - ‘20B_checkpoints/global_step150000/layer_13-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:34:09--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_13-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_13-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  9.64MB/s    in 39s     \n",
            "\n",
            "2022-07-28 05:34:49 (11.0 MB/s) - ‘20B_checkpoints/global_step150000/layer_13-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:34:49--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_14-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_14-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  8.34MB/s    in 44s     \n",
            "\n",
            "2022-07-28 05:35:33 (9.79 MB/s) - ‘20B_checkpoints/global_step150000/layer_14-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:35:33--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_14-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_14-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  11.9MB/s    in 44s     \n",
            "\n",
            "2022-07-28 05:36:18 (9.72 MB/s) - ‘20B_checkpoints/global_step150000/layer_14-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:36:18--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_15-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_15-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  7.74MB/s    in 37s     \n",
            "\n",
            "2022-07-28 05:36:55 (11.7 MB/s) - ‘20B_checkpoints/global_step150000/layer_15-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:36:55--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_15-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_15-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  10.5MB/s    in 61s     \n",
            "\n",
            "2022-07-28 05:37:57 (7.03 MB/s) - ‘20B_checkpoints/global_step150000/layer_15-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:37:57--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_16-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_16-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  12.2MB/s    in 34s     \n",
            "\n",
            "2022-07-28 05:38:31 (12.7 MB/s) - ‘20B_checkpoints/global_step150000/layer_16-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:38:31--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_16-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_16-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.2MB/s    in 37s     \n",
            "\n",
            "2022-07-28 05:39:09 (11.7 MB/s) - ‘20B_checkpoints/global_step150000/layer_16-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:39:09--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_17-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_17-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  9.68MB/s    in 40s     \n",
            "\n",
            "2022-07-28 05:39:49 (10.7 MB/s) - ‘20B_checkpoints/global_step150000/layer_17-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:39:49--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_17-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_17-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  11.1MB/s    in 36s     \n",
            "\n",
            "2022-07-28 05:40:25 (12.1 MB/s) - ‘20B_checkpoints/global_step150000/layer_17-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:40:25--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_18-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_18-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.5MB/s    in 41s     \n",
            "\n",
            "2022-07-28 05:41:07 (10.5 MB/s) - ‘20B_checkpoints/global_step150000/layer_18-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:41:07--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_18-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_18-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  7.29MB/s    in 38s     \n",
            "\n",
            "2022-07-28 05:41:45 (11.4 MB/s) - ‘20B_checkpoints/global_step150000/layer_18-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:41:45--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_19-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_19-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  11.7MB/s    in 44s     \n",
            "\n",
            "2022-07-28 05:42:29 (9.89 MB/s) - ‘20B_checkpoints/global_step150000/layer_19-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:42:29--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_19-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_19-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.1MB/s    in 45s     \n",
            "\n",
            "2022-07-28 05:43:14 (9.59 MB/s) - ‘20B_checkpoints/global_step150000/layer_19-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:43:14--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_20-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_20-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.2MB/s    in 33s     \n",
            "\n",
            "2022-07-28 05:43:48 (13.2 MB/s) - ‘20B_checkpoints/global_step150000/layer_20-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:43:48--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_20-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_20-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  11.8MB/s    in 33s     \n",
            "\n",
            "2022-07-28 05:44:21 (13.0 MB/s) - ‘20B_checkpoints/global_step150000/layer_20-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:44:21--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_21-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_21-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  12.1MB/s    in 36s     \n",
            "\n",
            "2022-07-28 05:44:58 (11.9 MB/s) - ‘20B_checkpoints/global_step150000/layer_21-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:44:58--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_21-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_21-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  10.0MB/s    in 51s     \n",
            "\n",
            "2022-07-28 05:45:49 (8.54 MB/s) - ‘20B_checkpoints/global_step150000/layer_21-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:45:49--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_22-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_22-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.6MB/s    in 37s     \n",
            "\n",
            "2022-07-28 05:46:27 (11.5 MB/s) - ‘20B_checkpoints/global_step150000/layer_22-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:46:27--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_22-model_01-model_states.pt\n",
            "Connecting to the-eye.eu (the-eye.eu)|162.213.130.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_22-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  9.07MB/s    in 52s     \n",
            "\n",
            "2022-07-28 05:47:20 (8.35 MB/s) - ‘20B_checkpoints/global_step150000/layer_22-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:47:20--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_23-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_23-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  8.67MB/s    in 50s     \n",
            "\n",
            "2022-07-28 05:48:10 (8.63 MB/s) - ‘20B_checkpoints/global_step150000/layer_23-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:48:10--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_23-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_23-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  7.44MB/s    in 54s     \n",
            "\n",
            "2022-07-28 05:49:05 (7.98 MB/s) - ‘20B_checkpoints/global_step150000/layer_23-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:49:05--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_24-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_24-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  9.48MB/s    in 49s     \n",
            "\n",
            "2022-07-28 05:49:55 (8.78 MB/s) - ‘20B_checkpoints/global_step150000/layer_24-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:49:55--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_24-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_24-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  8.79MB/s    in 55s     \n",
            "\n",
            "2022-07-28 05:50:50 (7.89 MB/s) - ‘20B_checkpoints/global_step150000/layer_24-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:50:50--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_25-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_25-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  6.73MB/s    in 76s     \n",
            "\n",
            "2022-07-28 05:52:06 (5.69 MB/s) - ‘20B_checkpoints/global_step150000/layer_25-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:52:06--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_25-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_25-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  11.7MB/s    in 70s     \n",
            "\n",
            "2022-07-28 05:53:16 (6.22 MB/s) - ‘20B_checkpoints/global_step150000/layer_25-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:53:16--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_26-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_26-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  7.41MB/s    in 57s     \n",
            "\n",
            "2022-07-28 05:54:13 (7.64 MB/s) - ‘20B_checkpoints/global_step150000/layer_26-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:54:13--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_26-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_26-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  3.64MB/s    in 79s     \n",
            "\n",
            "2022-07-28 05:55:32 (5.50 MB/s) - ‘20B_checkpoints/global_step150000/layer_26-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:55:32--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_27-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_27-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  8.93MB/s    in 72s     \n",
            "\n",
            "2022-07-28 05:56:44 (6.03 MB/s) - ‘20B_checkpoints/global_step150000/layer_27-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:56:44--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_27-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_27-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  12.9MB/s    in 42s     \n",
            "\n",
            "2022-07-28 05:57:26 (10.4 MB/s) - ‘20B_checkpoints/global_step150000/layer_27-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:57:26--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_28-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_28-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  11.0MB/s    in 39s     \n",
            "\n",
            "2022-07-28 05:58:06 (11.0 MB/s) - ‘20B_checkpoints/global_step150000/layer_28-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:58:06--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_28-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_28-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.1MB/s    in 38s     \n",
            "\n",
            "2022-07-28 05:58:46 (11.5 MB/s) - ‘20B_checkpoints/global_step150000/layer_28-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:58:46--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_29-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_29-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  10.2MB/s    in 46s     \n",
            "\n",
            "2022-07-28 05:59:32 (9.48 MB/s) - ‘20B_checkpoints/global_step150000/layer_29-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 05:59:32--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_29-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_29-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  5.71MB/s    in 47s     \n",
            "\n",
            "2022-07-28 06:00:19 (9.27 MB/s) - ‘20B_checkpoints/global_step150000/layer_29-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:00:19--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_30-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_30-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  7.66MB/s    in 48s     \n",
            "\n",
            "2022-07-28 06:01:07 (8.92 MB/s) - ‘20B_checkpoints/global_step150000/layer_30-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:01:07--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_30-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_30-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  9.01MB/s    in 57s     \n",
            "\n",
            "2022-07-28 06:02:05 (7.57 MB/s) - ‘20B_checkpoints/global_step150000/layer_30-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:02:05--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_31-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_31-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  11.0MB/s    in 45s     \n",
            "\n",
            "2022-07-28 06:02:50 (9.64 MB/s) - ‘20B_checkpoints/global_step150000/layer_31-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:02:50--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_31-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_31-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  12.9MB/s    in 41s     \n",
            "\n",
            "2022-07-28 06:03:32 (10.5 MB/s) - ‘20B_checkpoints/global_step150000/layer_31-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:03:32--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_32-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_32-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  9.54MB/s    in 60s     \n",
            "\n",
            "2022-07-28 06:04:32 (7.23 MB/s) - ‘20B_checkpoints/global_step150000/layer_32-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:04:32--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_32-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_32-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  7.71MB/s    in 54s     \n",
            "\n",
            "2022-07-28 06:05:26 (8.07 MB/s) - ‘20B_checkpoints/global_step150000/layer_32-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:05:26--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_33-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_33-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  12.2MB/s    in 43s     \n",
            "\n",
            "2022-07-28 06:06:09 (10.1 MB/s) - ‘20B_checkpoints/global_step150000/layer_33-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:06:09--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_33-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_33-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  11.4MB/s    in 43s     \n",
            "\n",
            "2022-07-28 06:06:52 (10.1 MB/s) - ‘20B_checkpoints/global_step150000/layer_33-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:06:52--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_34-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_34-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  6.84MB/s    in 50s     \n",
            "\n",
            "2022-07-28 06:07:42 (8.71 MB/s) - ‘20B_checkpoints/global_step150000/layer_34-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:07:42--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_34-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_34-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  7.06MB/s    in 56s     \n",
            "\n",
            "2022-07-28 06:08:38 (7.77 MB/s) - ‘20B_checkpoints/global_step150000/layer_34-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:08:38--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_35-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_35-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  11.5MB/s    in 55s     \n",
            "\n",
            "2022-07-28 06:09:33 (7.92 MB/s) - ‘20B_checkpoints/global_step150000/layer_35-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:09:33--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_35-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_35-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  12.5MB/s    in 38s     \n",
            "\n",
            "2022-07-28 06:10:11 (11.5 MB/s) - ‘20B_checkpoints/global_step150000/layer_35-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:10:11--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_36-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_36-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  10.8MB/s    in 46s     \n",
            "\n",
            "2022-07-28 06:10:58 (9.30 MB/s) - ‘20B_checkpoints/global_step150000/layer_36-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:10:58--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_36-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_36-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  6.38MB/s    in 95s     \n",
            "\n",
            "2022-07-28 06:12:33 (4.56 MB/s) - ‘20B_checkpoints/global_step150000/layer_36-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:12:33--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_37-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_37-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  7.65MB/s    in 71s     \n",
            "\n",
            "2022-07-28 06:13:45 (6.05 MB/s) - ‘20B_checkpoints/global_step150000/layer_37-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:13:45--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_37-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_37-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.7MB/s    in 50s     \n",
            "\n",
            "2022-07-28 06:14:35 (8.73 MB/s) - ‘20B_checkpoints/global_step150000/layer_37-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:14:35--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_38-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_38-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.5MB/s    in 34s     \n",
            "\n",
            "2022-07-28 06:15:09 (12.8 MB/s) - ‘20B_checkpoints/global_step150000/layer_38-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:15:09--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_38-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_38-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.4MB/s    in 38s     \n",
            "\n",
            "2022-07-28 06:15:47 (11.3 MB/s) - ‘20B_checkpoints/global_step150000/layer_38-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:15:47--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_39-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_39-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  12.0MB/s    in 43s     \n",
            "\n",
            "2022-07-28 06:16:31 (10.0 MB/s) - ‘20B_checkpoints/global_step150000/layer_39-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:16:31--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_39-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_39-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.3MB/s    in 34s     \n",
            "\n",
            "2022-07-28 06:17:05 (12.9 MB/s) - ‘20B_checkpoints/global_step150000/layer_39-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:17:05--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_40-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_40-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  12.3MB/s    in 36s     \n",
            "\n",
            "2022-07-28 06:17:41 (12.0 MB/s) - ‘20B_checkpoints/global_step150000/layer_40-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:17:41--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_40-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_40-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  12.6MB/s    in 37s     \n",
            "\n",
            "2022-07-28 06:18:18 (11.8 MB/s) - ‘20B_checkpoints/global_step150000/layer_40-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:18:18--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_41-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_41-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.2MB/s    in 34s     \n",
            "\n",
            "2022-07-28 06:18:52 (12.8 MB/s) - ‘20B_checkpoints/global_step150000/layer_41-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:18:52--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_41-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_41-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  11.8MB/s    in 42s     \n",
            "\n",
            "2022-07-28 06:19:35 (10.3 MB/s) - ‘20B_checkpoints/global_step150000/layer_41-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:19:35--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_42-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_42-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.1MB/s    in 33s     \n",
            "\n",
            "2022-07-28 06:20:08 (13.0 MB/s) - ‘20B_checkpoints/global_step150000/layer_42-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:20:08--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_42-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_42-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  13.7MB/s    in 33s     \n",
            "\n",
            "2022-07-28 06:20:41 (13.1 MB/s) - ‘20B_checkpoints/global_step150000/layer_42-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:20:41--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_43-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_43-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  7.95MB/s    in 62s     \n",
            "\n",
            "2022-07-28 06:21:44 (6.96 MB/s) - ‘20B_checkpoints/global_step150000/layer_43-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:21:44--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_43-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_43-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  8.71MB/s    in 64s     \n",
            "\n",
            "2022-07-28 06:22:48 (6.76 MB/s) - ‘20B_checkpoints/global_step150000/layer_43-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:22:48--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_44-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_44-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  5.16MB/s    in 93s     \n",
            "\n",
            "2022-07-28 06:24:23 (4.65 MB/s) - ‘20B_checkpoints/global_step150000/layer_44-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:24:23--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_44-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_44-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  7.27MB/s    in 74s     \n",
            "\n",
            "2022-07-28 06:25:38 (5.86 MB/s) - ‘20B_checkpoints/global_step150000/layer_44-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:25:38--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_45-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_45-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  12.8MB/s    in 41s     \n",
            "\n",
            "2022-07-28 06:26:20 (10.5 MB/s) - ‘20B_checkpoints/global_step150000/layer_45-model_00-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:26:20--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_45-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 453105150 (432M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_45-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 432.11M  9.08MB/s    in 81s     \n",
            "\n",
            "2022-07-28 06:27:41 (5.34 MB/s) - ‘20B_checkpoints/global_step150000/layer_45-model_01-model_states.pt’ saved [453105150/453105150]\n",
            "\n",
            "--2022-07-28 06:27:41--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_47-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25511 (25K) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_47-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>]  24.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 06:27:41 (275 MB/s) - ‘20B_checkpoints/global_step150000/layer_47-model_00-model_states.pt’ saved [25511/25511]\n",
            "\n",
            "--2022-07-28 06:27:41--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_47-model_01-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25511 (25K) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_47-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>]  24.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 06:27:41 (253 MB/s) - ‘20B_checkpoints/global_step150000/layer_47-model_01-model_states.pt’ saved [25511/25511]\n",
            "\n",
            "--2022-07-28 06:27:41--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_48-model_00-model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 309854955 (296M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_48-model_00-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 295.50M  12.9MB/s    in 34s     \n",
            "\n",
            "2022-07-28 06:28:16 (8.75 MB/s) - ‘20B_checkpoints/global_step150000/layer_48-model_00-model_states.pt’ saved [309854955/309854955]\n",
            "\n",
            "--2022-07-28 06:28:16--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/layer_48-model_01-model_states.pt\n",
            "Connecting to the-eye.eu (the-eye.eu)|162.213.130.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 309854955 (296M) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/layer_48-model_01-model_states.pt’\n",
            "\n",
            "global_step150000/l 100%[===================>] 295.50M  11.5MB/s    in 26s     \n",
            "\n",
            "2022-07-28 06:28:43 (11.5 MB/s) - ‘20B_checkpoints/global_step150000/layer_48-model_01-model_states.pt’ saved [309854955/309854955]\n",
            "\n",
            "--2022-07-28 06:28:43--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/mp_rank_00_model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16291 (16K) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/mp_rank_00_model_states.pt’\n",
            "\n",
            "global_step150000/m 100%[===================>]  15.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 06:28:43 (282 MB/s) - ‘20B_checkpoints/global_step150000/mp_rank_00_model_states.pt’ saved [16291/16291]\n",
            "\n",
            "--2022-07-28 06:28:43--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/mp_rank_01_model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16291 (16K) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/mp_rank_01_model_states.pt’\n",
            "\n",
            "global_step150000/m 100%[===================>]  15.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 06:28:43 (286 MB/s) - ‘20B_checkpoints/global_step150000/mp_rank_01_model_states.pt’ saved [16291/16291]\n",
            "\n",
            "--2022-07-28 06:28:43--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/mp_rank_02_model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16291 (16K) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/mp_rank_02_model_states.pt’\n",
            "\n",
            "global_step150000/m 100%[===================>]  15.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 06:28:44 (242 MB/s) - ‘20B_checkpoints/global_step150000/mp_rank_02_model_states.pt’ saved [16291/16291]\n",
            "\n",
            "--2022-07-28 06:28:44--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/mp_rank_03_model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16291 (16K) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/mp_rank_03_model_states.pt’\n",
            "\n",
            "global_step150000/m 100%[===================>]  15.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 06:28:44 (237 MB/s) - ‘20B_checkpoints/global_step150000/mp_rank_03_model_states.pt’ saved [16291/16291]\n",
            "\n",
            "--2022-07-28 06:28:44--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/mp_rank_04_model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16227 (16K) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/mp_rank_04_model_states.pt’\n",
            "\n",
            "global_step150000/m 100%[===================>]  15.85K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 06:28:44 (289 MB/s) - ‘20B_checkpoints/global_step150000/mp_rank_04_model_states.pt’ saved [16227/16227]\n",
            "\n",
            "--2022-07-28 06:28:44--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/mp_rank_05_model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16227 (16K) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/mp_rank_05_model_states.pt’\n",
            "\n",
            "global_step150000/m 100%[===================>]  15.85K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 06:28:44 (149 MB/s) - ‘20B_checkpoints/global_step150000/mp_rank_05_model_states.pt’ saved [16227/16227]\n",
            "\n",
            "--2022-07-28 06:28:44--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/mp_rank_06_model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16291 (16K) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/mp_rank_06_model_states.pt’\n",
            "\n",
            "global_step150000/m 100%[===================>]  15.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 06:28:45 (274 MB/s) - ‘20B_checkpoints/global_step150000/mp_rank_06_model_states.pt’ saved [16291/16291]\n",
            "\n",
            "--2022-07-28 06:28:45--  https://the-eye.eu/public/AI/models/GPT-NeoX-20B/slim_weights/global_step150000/mp_rank_07_model_states.pt\n",
            "Reusing existing connection to the-eye.eu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16291 (16K) [application/octet-stream]\n",
            "Saving to: ‘20B_checkpoints/global_step150000/mp_rank_07_model_states.pt’\n",
            "\n",
            "global_step150000/m 100%[===================>]  15.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 06:28:45 (91.0 MB/s) - ‘20B_checkpoints/global_step150000/mp_rank_07_model_states.pt’ saved [16291/16291]\n",
            "\n",
            "FINISHED --2022-07-28 06:28:45--\n",
            "Total wall clock time: 1h 12m 35s\n",
            "Downloaded: 108 files, 38G in 1h 11m 45s (9.11 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 환경설정"
      ],
      "metadata": {
        "id": "3ssbLNAPluIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r gpt-neox/requirements/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg5kqKb5IaOU",
        "outputId": "75f19312-9624-4720-9c33-a802cab5b840"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepspeed\n",
            "  Cloning https://github.com/EleutherAI/DeeperSpeed.git (to revision eb7f5cff36678625d23db8a8fe78b4a93e5d2c75) to /tmp/pip-install-5klsz9nn/deepspeed_252ff80c3e2a4af7b0af3cd53e0e7e98\n",
            "  Running command git clone -q https://github.com/EleutherAI/DeeperSpeed.git /tmp/pip-install-5klsz9nn/deepspeed_252ff80c3e2a4af7b0af3cd53e0e7e98\n",
            "  Running command git rev-parse -q --verify 'sha^eb7f5cff36678625d23db8a8fe78b4a93e5d2c75'\n",
            "  Running command git fetch -q https://github.com/EleutherAI/DeeperSpeed.git eb7f5cff36678625d23db8a8fe78b4a93e5d2c75\n",
            "  Running command git checkout -q eb7f5cff36678625d23db8a8fe78b4a93e5d2c75\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Collecting einops==0.3.0\n",
            "  Using cached einops-0.3.0-py2.py3-none-any.whl (25 kB)\n",
            "Collecting ftfy==6.0.1\n",
            "  Using cached ftfy-6.0.1.tar.gz (63 kB)\n",
            "Collecting lm_dataformat==0.0.20\n",
            "  Using cached lm_dataformat-0.0.20-py3-none-any.whl (5.8 kB)\n",
            "Collecting lm_eval==0.2.0\n",
            "  Using cached lm_eval-0.2.0-py3-none-any.whl (143 kB)\n",
            "Collecting mpi4py==3.0.3\n",
            "  Using cached mpi4py-3.0.3.tar.gz (1.4 MB)\n",
            "Requirement already satisfied: numpy==1.21.6 in /usr/local/lib/python3.7/dist-packages (from -r gpt-neox/requirements/requirements.txt (line 8)) (1.21.6)\n",
            "Collecting pybind11==2.6.2\n",
            "  Downloading pybind11-2.6.2-py2.py3-none-any.whl (191 kB)\n",
            "\u001b[K     |████████████████████████████████| 191 kB 31.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from -r gpt-neox/requirements/requirements.txt (line 10)) (2022.6.2)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 64.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from -r gpt-neox/requirements/requirements.txt (line 12)) (1.15.0)\n",
            "Collecting tokenizers==0.10.2\n",
            "  Downloading tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 58.5 MB/s \n",
            "\u001b[?25hCollecting transformers~=4.16.0\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 59.5 MB/s \n",
            "\u001b[?25hCollecting wandb==0.10.28\n",
            "  Downloading wandb-0.10.28-py2.py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from deepspeed->-r gpt-neox/requirements/requirements.txt (line 1)) (1.12.0+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deepspeed->-r gpt-neox/requirements/requirements.txt (line 1)) (4.64.0)\n",
            "Collecting tensorboardX==1.8\n",
            "  Downloading tensorboardX-1.8-py2.py3-none-any.whl (216 kB)\n",
            "\u001b[K     |████████████████████████████████| 216 kB 73.6 MB/s \n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 72.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from deepspeed->-r gpt-neox/requirements/requirements.txt (line 1)) (5.4.8)\n",
            "Collecting triton==0.4.2\n",
            "  Downloading triton-0.4.2-cp37-cp37m-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 85 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy==6.0.1->-r gpt-neox/requirements/requirements.txt (line 3)) (0.2.5)\n",
            "Collecting zstandard\n",
            "  Downloading zstandard-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 63.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ujson in /usr/local/lib/python3.7/dist-packages (from lm_dataformat==0.0.20->-r gpt-neox/requirements/requirements.txt (line 4)) (5.4.0)\n",
            "Collecting jsonlines\n",
            "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: jieba==0.42.1 in /usr/local/lib/python3.7/dist-packages (from lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (0.42.1)\n",
            "Collecting datasets==1.15.1\n",
            "  Downloading datasets-1.15.1-py3-none-any.whl (290 kB)\n",
            "\u001b[K     |████████████████████████████████| 290 kB 63.9 MB/s \n",
            "\u001b[?25hCollecting numexpr==2.7.2\n",
            "  Downloading numexpr-2.7.2-cp37-cp37m-manylinux2010_x86_64.whl (471 kB)\n",
            "\u001b[K     |████████████████████████████████| 471 kB 64.5 MB/s \n",
            "\u001b[?25hCollecting rouge-score==0.0.4\n",
            "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
            "Collecting sqlitedict==1.6.0\n",
            "  Downloading sqlitedict-1.6.0.tar.gz (29 kB)\n",
            "Collecting best-download==0.0.9\n",
            "  Downloading best_download-0.0.9-py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.7/dist-packages (from lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (1.0.2)\n",
            "Collecting sacrebleu==1.5.0\n",
            "  Downloading sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.1 in /usr/local/lib/python3.7/dist-packages (from lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (7.1.2)\n",
            "Collecting jsonlines\n",
            "  Downloading jsonlines-2.0.0-py3-none-any.whl (6.3 kB)\n",
            "Collecting nagisa==0.2.7\n",
            "  Downloading nagisa-0.2.7-cp37-cp37m-manylinux1_x86_64.whl (21.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.5 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting pytablewriter==0.58.0\n",
            "  Downloading pytablewriter-0.58.0-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting mock==4.0.3\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Collecting tqdm-multiprocess==0.0.11\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Collecting pycountry==20.7.3\n",
            "  Downloading pycountry-20.7.3.tar.gz (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 59.0 MB/s \n",
            "\u001b[?25hCollecting pytest==6.2.3\n",
            "  Downloading pytest-6.2.3-py3-none-any.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 69.1 MB/s \n",
            "\u001b[?25hCollecting black\n",
            "  Downloading black-22.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 64.0 MB/s \n",
            "\u001b[?25hCollecting openai==0.6.4\n",
            "  Downloading openai-0.6.4.tar.gz (159 kB)\n",
            "\u001b[K     |████████████████████████████████| 159 kB 41.0 MB/s \n",
            "\u001b[?25hCollecting zstandard\n",
            "  Downloading zstandard-0.15.2-cp37-cp37m-manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 70.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.28->-r gpt-neox/requirements/requirements.txt (line 15)) (2.8.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.28->-r gpt-neox/requirements/requirements.txt (line 15)) (3.13)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.28->-r gpt-neox/requirements/requirements.txt (line 15)) (2.23.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.28->-r gpt-neox/requirements/requirements.txt (line 15)) (3.17.3)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.28->-r gpt-neox/requirements/requirements.txt (line 15)) (2.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "  Downloading sentry_sdk-1.8.0-py2.py3-none-any.whl (153 kB)\n",
            "\u001b[K     |████████████████████████████████| 153 kB 60.7 MB/s \n",
            "\u001b[?25hCollecting rehash\n",
            "  Downloading rehash-1.0.0-py2.py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets==1.15.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (21.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.15.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (0.3.5.1)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.7.0-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 68.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets==1.15.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (3.8.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 71.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.15.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (6.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.15.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (1.3.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.15.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (0.70.13)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.15.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (4.12.0)\n",
            "Collecting DyNet\n",
            "  Downloading dyNET-2.1.2-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 19.6 MB/s \n",
            "\u001b[?25hCollecting typepy[datetime]<2,>=1.1.1\n",
            "  Downloading typepy-1.3.0-py3-none-any.whl (31 kB)\n",
            "Collecting tabledata<2,>=1.1.3\n",
            "  Downloading tabledata-1.3.0-py3-none-any.whl (11 kB)\n",
            "Collecting msgfy<1,>=0.1.0\n",
            "  Downloading msgfy-0.2.0-py3-none-any.whl (4.3 kB)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.7/dist-packages (from pytablewriter==0.58.0->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (57.4.0)\n",
            "Collecting tcolorpy<1,>=0.0.5\n",
            "  Downloading tcolorpy-0.1.2-py3-none-any.whl (7.9 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0\n",
            "  Downloading mbstrdecoder-1.1.0-py3-none-any.whl (7.8 kB)\n",
            "Collecting pathvalidate<3,>=2.3.0\n",
            "  Downloading pathvalidate-2.5.0-py3-none-any.whl (19 kB)\n",
            "Collecting DataProperty<2,>=0.50.0\n",
            "  Downloading DataProperty-0.55.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest==6.2.3->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (1.11.0)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest==6.2.3->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (1.1.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest==6.2.3->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (21.4.0)\n",
            "Collecting pluggy<1.0.0a1,>=0.12\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score==0.0.4->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (3.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score==0.0.4->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (1.2.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Collecting PyYAML\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 71.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 64.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers~=4.16.0->-r gpt-neox/requirements/requirements.txt (line 14)) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb==0.10.28->-r gpt-neox/requirements/requirements.txt (line 15)) (4.1.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.15.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (3.8.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter==0.58.0->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets==1.15.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb==0.10.28->-r gpt-neox/requirements/requirements.txt (line 15)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb==0.10.28->-r gpt-neox/requirements/requirements.txt (line 15)) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb==0.10.28->-r gpt-neox/requirements/requirements.txt (line 15)) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.7/dist-packages (from typepy[datetime]<2,>=1.1.1->pytablewriter==0.58.0->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (2022.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.15.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.15.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.15.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (2.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.15.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (1.7.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.15.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.15.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.15.1->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (4.0.2)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting platformdirs>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from black->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (2.0.1)\n",
            "Collecting click>=7.1\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.5.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 64.3 MB/s \n",
            "\u001b[?25hCollecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from DyNet->nagisa==0.2.7->lm_eval==0.2.0->-r gpt-neox/requirements/requirements.txt (line 5)) (0.29.30)\n",
            "Building wheels for collected packages: deepspeed, ftfy, mpi4py, openai, pycountry, sqlitedict, subprocess32, pathtools, sacremoses\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.3.15+eb7f5cf-py3-none-any.whl size=419318 sha256=3db5509544fb438a2da5d8726063f141793fa546c856f53d32b04e71a929fd43\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/94/ec/33b563da30d53ed5057bb84d576d620523680fbfb566abdbe5\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.1-py3-none-any.whl size=41590 sha256=5a0c89b6544f3fa2eb0c37514853d878704e7edea116914ef44b908922cbe94e\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/10/8d/092bc0016be4948c3fe65c4a3e1354ac39ca7eff07e9f2df25\n",
            "  Building wheel for mpi4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.0.3-cp37-cp37m-linux_x86_64.whl size=2065434 sha256=98d2d3106e21351b3f05a6db6ebbd6e84de2f0dcaa1deed0d953b7179f265e04\n",
            "  Stored in directory: /root/.cache/pip/wheels/da/37/ee/8d5c9166a378bb0b661bf4257b8e1ef8d79d879b931534fb98\n",
            "  Building wheel for openai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.6.4-py3-none-any.whl size=172215 sha256=cab96ffc6f3525008db514a3d4d4a255be83f895df1e960f49ce18d7346e2ac5\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/c4/02/aa519fe2aaf97a9bba197a8585182c8c07802760351afdb64a\n",
            "  Building wheel for pycountry (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-20.7.3-py2.py3-none-any.whl size=10746882 sha256=c9ed9f7c6460078ea5a78a09f53fb0b02e06a89de8ee11a7e855b7611eb0c752\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/e8/3f/120ccc1ff7541c108bc5d656e2a14c39da0d824653b62284c6\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-py3-none-any.whl size=14712 sha256=826ad2a32e623a7847728094ed11f925013841afb6db0920c642ca559400ebb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/dd/2c/0a57aadf6a7f26bec0af66d742c50af74d11967780f0bb7a7d\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=991f9c0e6eab622d8f4c6023c7d2951e2412f7bb16cdc2280993ce8a81fd42a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=3d1dde14c6e428eaefcbd29acfd40fa1e8c9b949e884c69a8984d09ac10d874d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=ce9b95e996fc631139192f041bf406a6baf5748a812c7e7ac3489f44763740a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built deepspeed ftfy mpi4py openai pycountry sqlitedict subprocess32 pathtools sacremoses\n",
            "Installing collected packages: mbstrdecoder, typepy, smmap, PyYAML, fsspec, DataProperty, click, zstandard, xxhash, typed-ast, toml, tokenizers, tcolorpy, tabledata, sacremoses, rehash, portalocker, pluggy, platformdirs, pathvalidate, pathspec, mypy-extensions, msgfy, jsonlines, huggingface-hub, gitdb, DyNet, colorama, triton, transformers, tqdm-multiprocess, tensorboardX, subprocess32, sqlitedict, shortuuid, sentry-sdk, sacrebleu, rouge-score, pytest, pytablewriter, pycountry, pybind11, pathtools, openai, numexpr, ninja, nagisa, mock, lm-dataformat, GitPython, docker-pycreds, datasets, configparser, black, best-download, wandb, sentencepiece, mpi4py, lm-eval, ftfy, einops, deepspeed\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Attempting uninstall: numexpr\n",
            "    Found existing installation: numexpr 2.8.3\n",
            "    Uninstalling numexpr-2.8.3:\n",
            "      Successfully uninstalled numexpr-2.8.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed DataProperty-0.55.0 DyNet-2.1.2 GitPython-3.1.27 PyYAML-6.0 best-download-0.0.9 black-22.6.0 click-8.1.3 colorama-0.4.5 configparser-5.2.0 datasets-1.15.1 deepspeed-0.3.15+eb7f5cf docker-pycreds-0.4.0 einops-0.3.0 fsspec-2022.7.0 ftfy-6.0.1 gitdb-4.0.9 huggingface-hub-0.8.1 jsonlines-2.0.0 lm-dataformat-0.0.20 lm-eval-0.2.0 mbstrdecoder-1.1.0 mock-4.0.3 mpi4py-3.0.3 msgfy-0.2.0 mypy-extensions-0.4.3 nagisa-0.2.7 ninja-1.10.2.3 numexpr-2.7.2 openai-0.6.4 pathspec-0.9.0 pathtools-0.1.2 pathvalidate-2.5.0 platformdirs-2.5.2 pluggy-0.13.1 portalocker-2.5.1 pybind11-2.6.2 pycountry-20.7.3 pytablewriter-0.58.0 pytest-6.2.3 rehash-1.0.0 rouge-score-0.0.4 sacrebleu-1.5.0 sacremoses-0.0.53 sentencepiece-0.1.96 sentry-sdk-1.8.0 shortuuid-1.0.9 smmap-5.0.0 sqlitedict-1.6.0 subprocess32-3.5.4 tabledata-1.3.0 tcolorpy-0.1.2 tensorboardX-1.8 tokenizers-0.10.2 toml-0.10.2 tqdm-multiprocess-0.0.11 transformers-4.16.2 triton-0.4.2 typed-ast-1.5.4 typepy-1.3.0 wandb-0.10.28 xxhash-3.0.0 zstandard-0.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python gpt-neox/megatron/fused_kernels/setup.py install # optional if not using fused kernels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiNf824DI6ML",
        "outputId": "53b37360-ebaa-48d0-9103-afb5d86a9a0d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating fused_kernels.egg-info\n",
            "writing fused_kernels.egg-info/PKG-INFO\n",
            "writing dependency_links to fused_kernels.egg-info/dependency_links.txt\n",
            "writing top-level names to fused_kernels.egg-info/top_level.txt\n",
            "writing manifest file 'fused_kernels.egg-info/SOURCES.txt'\n",
            "reading manifest file 'fused_kernels.egg-info/SOURCES.txt'\n",
            "writing manifest file 'fused_kernels.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:813: UserWarning: The detected CUDA version (11.1) has a minor version mismatch with the version that was used to compile PyTorch (11.3). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "building 'scaled_upper_triang_masked_softmax_cuda' extension\n",
            "creating /content/build\n",
            "creating /content/build/temp.linux-x86_64-3.7\n",
            "creating /content/build/temp.linux-x86_64-3.7/content\n",
            "creating /content/build/temp.linux-x86_64-3.7/content/gpt-neox\n",
            "creating /content/build/temp.linux-x86_64-3.7/content/gpt-neox/megatron\n",
            "creating /content/build/temp.linux-x86_64-3.7/content/gpt-neox/megatron/fused_kernels\n",
            "Emitting ninja build file /content/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "Compiling objects...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "[1/2] c++ -MMD -MF /content/build/temp.linux-x86_64-3.7/content/gpt-neox/megatron/fused_kernels/scaled_upper_triang_masked_softmax.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/gpt-neox/megatron/fused_kernels/scaled_upper_triang_masked_softmax.cpp -o /content/build/temp.linux-x86_64-3.7/content/gpt-neox/megatron/fused_kernels/scaled_upper_triang_masked_softmax.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1013\"' -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "[2/2] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/gpt-neox/megatron/fused_kernels/scaled_upper_triang_masked_softmax_cuda.cu -o /content/build/temp.linux-x86_64-3.7/content/gpt-neox/megatron/fused_kernels/scaled_upper_triang_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -gencode arch=compute_70,code=sm_70 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -gencode arch=compute_80,code=sm_80 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1013\"' -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/SymInt.h(84): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/SymInt.h(84): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/SymInt.h(84): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/build/temp.linux-x86_64-3.7/content/gpt-neox/megatron/fused_kernels/scaled_upper_triang_masked_softmax.o /content/build/temp.linux-x86_64-3.7/content/gpt-neox/megatron/fused_kernels/scaled_upper_triang_masked_softmax_cuda.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/scaled_upper_triang_masked_softmax_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "building 'scaled_masked_softmax_cuda' extension\n",
            "Emitting ninja build file /content/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "Compiling objects...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "[1/2] c++ -MMD -MF /content/build/temp.linux-x86_64-3.7/content/gpt-neox/megatron/fused_kernels/scaled_masked_softmax.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/gpt-neox/megatron/fused_kernels/scaled_masked_softmax.cpp -o /content/build/temp.linux-x86_64-3.7/content/gpt-neox/megatron/fused_kernels/scaled_masked_softmax.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1013\"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "[2/2] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/gpt-neox/megatron/fused_kernels/scaled_masked_softmax_cuda.cu -o /content/build/temp.linux-x86_64-3.7/content/gpt-neox/megatron/fused_kernels/scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -gencode arch=compute_70,code=sm_70 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -gencode arch=compute_80,code=sm_80 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1013\"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/SymInt.h(84): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/content/gpt-neox/megatron/fused_kernels/scaled_masked_softmax.h(343): warning: variable \"batch_count\" was declared but never referenced\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/SymInt.h(84): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/content/gpt-neox/megatron/fused_kernels/scaled_masked_softmax.h(343): warning: variable \"batch_count\" was declared but never referenced\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/SymInt.h(84): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/build/temp.linux-x86_64-3.7/content/gpt-neox/megatron/fused_kernels/scaled_masked_softmax.o /content/build/temp.linux-x86_64-3.7/content/gpt-neox/megatron/fused_kernels/scaled_masked_softmax_cuda.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/scaled_masked_softmax_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.7/scaled_upper_triang_masked_softmax_cuda.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.7/scaled_masked_softmax_cuda.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for scaled_upper_triang_masked_softmax_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for scaled_masked_softmax_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/scaled_upper_triang_masked_softmax_cuda.py to scaled_upper_triang_masked_softmax_cuda.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/scaled_masked_softmax_cuda.py to scaled_masked_softmax_cuda.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fused_kernels.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fused_kernels.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fused_kernels.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fused_kernels.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.scaled_masked_softmax_cuda.cpython-37: module references __file__\n",
            "__pycache__.scaled_upper_triang_masked_softmax_cuda.cpython-37: module references __file__\n",
            "creating dist\n",
            "creating 'dist/fused_kernels-0.0.1-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing fused_kernels-0.0.1-py3.7-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.7/dist-packages/fused_kernels-0.0.1-py3.7-linux-x86_64.egg\n",
            "Extracting fused_kernels-0.0.1-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding fused-kernels 0.0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/fused_kernels-0.0.1-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for fused-kernels==0.0.1\n",
            "Finished processing dependencies for fused-kernels==0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##파일실행/모델구동"
      ],
      "metadata": {
        "id": "Rd-Ax4UTlzAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gpt-neox/deepy.py gpt-neox/generate.py gpt-neox/configs/20B.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_TiWNduiHKG",
        "outputId": "b16b4f74-fe9c-421a-808e-67cf51981468"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "NeoXArgs.from_ymls() ['gpt-neox/configs/20B.yml']\n",
            "INFO:root:NeoXArgs.calculate_derived() Total number of GPUs determined to be: 1\n",
            "-------------------- arguments --------------------\n",
            "  attention_config ................ ['global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global']updated\n",
            "  attention_dropout ............... 0...........................updated\n",
            "  batch_size ...................... 16..........................updated\n",
            "  bias_gelu_fusion ................ True........................updated\n",
            "  checkpoint_activations .......... True........................updated\n",
            "  clip_grad ....................... 1.0.........................updated\n",
            "  config_files .................... {'20B.yml': '# DISCLAIMER: This is the configuration file for the GPT-NeoX-20B model as it was trained on 96x 40GB A100\\n# GPUs. Depending on your system configuration, you may need to change some parameters in order to fit\\n# the model in memory.\\n\\n{\\n  # Tokenizer /  checkpoint settings - you will need to change these to the location you have them saved in\\n  \"vocab-file\": \"gpt-neox/20B_checkpoints/20B_tokenizer.json\",\\n  \"save\": \"gpt-neox/20B_checkpoints\",\\n  \"load\": \"gpt-neox/20B_checkpoints\",\\n\\n  # If finetuning, edit the following to the location of your finetuning dataset:\\n  \"data-path\": \"./data/pile_20B_tokenizer/pile_20B_tokenizer_text_document\",\\n\\n  # parallelism settings ( you will want to change these based on your cluster setup, ideally scheduling pipeline stages\\n  # across the node boundaries )\\n  \"pipe-parallel-size\": 1,\\n  \"model-parallel-size\": 1,\\n\\n  # model settings\\n  \"num-layers\": 44,\\n  \"hidden-size\": 6144,\\n  \"num-attention-heads\": 64,\\n  \"seq-length\": 2048,\\n  \"max-position-embeddings\": 2048,\\n  \"norm\": \"layernorm\",\\n  \"pos-emb\": \"rotary\",\\n  \"rotary_pct\": 0.25,\\n  \"no-weight-tying\": true,\\n  \"gpt_j_residual\": true,\\n  \"output_layer_parallelism\": \"column\",\\n  \"scaled-upper-triang-masked-softmax-fusion\": true,\\n  \"bias-gelu-fusion\": true,\\n\\n  # init methods\\n  \"init_method\": \"small_init\",\\n  \"output_layer_init_method\": \"wang_init\",\\n\\n  # optimizer settings\\n  \"optimizer\": {\\n    \"type\": \"Adam\",\\n    \"params\": {\\n      \"lr\": 0.97e-4,\\n      \"betas\": [0.9, 0.95],\\n      \"eps\": 1.0e-8,\\n      }\\n      },\\n\\n  \"min_lr\": 0.97e-5,\\n  \"zero_optimization\": {\\n  \"stage\": 1,\\n  \"allgather_partitions\": True,\\n  \"allgather_bucket_size\": 1260000000,\\n  \"overlap_comm\": True,\\n  \"reduce_scatter\": True,\\n  \"reduce_bucket_size\": 1260000000,\\n  \"contiguous_gradients\": True,\\n  \"cpu_offload\": False\\n  },\\n\\n  # batch / data settings (assuming 96 GPUs)\\n  \"train_micro_batch_size_per_gpu\": 16,\\n  \"gradient_accumulation_steps\": 64,\\n  \"data-impl\": \"mmap\",\\n  \"split\": \"995,4,1\",\\n\\n  # activation checkpointing\\n  \"checkpoint-activations\": true,\\n  \"checkpoint-num-layers\": 1,\\n  \"partition-activations\": false,\\n  \"synchronize-each-layer\": true,\\n\\n  # regularization\\n  \"gradient_clipping\": 1.0,\\n  \"weight-decay\": 0.01,\\n  \"hidden-dropout\": 0,\\n  \"attention-dropout\": 0,\\n\\n  # precision settings\\n  \"fp16\": {\\n    \"fp16\": true,\\n    \"enabled\": true,\\n    \"loss_scale\": 0,\\n    \"loss_scale_window\": 1000,\\n    \"initial_scale_power\": 12,\\n    \"hysteresis\": 2,\\n    \"min_loss_scale\": 1\\n    },\\n\\n  # misc. training settings\\n  \"train-iters\": 150000,\\n  \"lr-decay-iters\": 150000,\\n\\n  \"distributed-backend\": \"nccl\",\\n  \"lr-decay-style\": \"cosine\",\\n  \"warmup\": 0.01,\\n  \"save-interval\": 500,\\n  \"eval-interval\": 1000,\\n  \"eval-iters\": 10,\\n\\n  # logging\\n  \"log-interval\": 2,\\n  \"steps_per_print\": 2,\\n  \"wall_clock_breakdown\": false,\\n\\n  ### NEW DATA: ####\\n  \"tokenizer_type\": \"HFTokenizer\",\\n  \"tensorboard-dir\": \"gpt-neox/tensorboard\",\\n  \"log-dir\": \"gpt-neox/logs\",\\n\\n}\\n'}updated\n",
            "  data_impl ....................... mmap........................updated\n",
            "  data_path ....................... ./data/pile_20B_tokenizer/pile_20B_tokenizer_text_documentupdated\n",
            "  dynamic_loss_scale .............. True........................updated\n",
            "  eval_iters ...................... 10..........................updated\n",
            "  fp16 ............................ {'fp16': True, 'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 12, 'hysteresis': 2, 'min_loss_scale': 1}updated\n",
            "  gas ............................. 64..........................updated\n",
            "  global_num_gpus ................. 1...........................updated\n",
            "  gpt_j_residual .................. True........................updated\n",
            "  gradient_accumulation_steps ..... 64..........................updated\n",
            "  gradient_clipping ............... 1.0.........................updated\n",
            "  hidden_dropout .................. 0...........................updated\n",
            "  hidden_size ..................... 6144........................updated\n",
            "  init_method ..................... small_init..................updated\n",
            "  is_pipe_parallel ................ True........................updated\n",
            "  load ............................ gpt-neox/20B_checkpoints....updated\n",
            "  log_dir ......................... gpt-neox/logs...............updated\n",
            "  log_interval .................... 2...........................updated\n",
            "  lr .............................. 9.7e-05.....................updated\n",
            "  lr_decay_iters .................. 150000......................updated\n",
            "  lr_decay_style .................. cosine......................updated\n",
            "  max_position_embeddings ......... 2048........................updated\n",
            "  min_lr .......................... 9.7e-06.....................updated\n",
            "  no_weight_tying ................. True........................updated\n",
            "  num_attention_heads ............. 64..........................updated\n",
            "  num_layers ...................... 44..........................updated\n",
            "  optimizer ....................... {'type': 'Adam', 'params': {'lr': 9.7e-05, 'betas': [0.9, 0.95], 'eps': 1e-08}}updated\n",
            "  optimizer_type .................. Adam........................updated\n",
            "  output_layer_init_method ........ wang_init...................updated\n",
            "  output_layer_parallelism ........ column......................updated\n",
            "  pipe_parallel_size .............. 1...........................updated\n",
            "  pos_emb ......................... rotary......................updated\n",
            "  precision ....................... fp16........................updated\n",
            "  rotary_pct ...................... 0.25........................updated\n",
            "  save ............................ gpt-neox/20B_checkpoints....updated\n",
            "  save_interval ................... 500.........................updated\n",
            "  scaled_upper_triang_masked_softmax_fusion  True...............updated\n",
            "  seq_length ...................... 2048........................updated\n",
            "  sparsity_config ................. {}..........................updated\n",
            "  split ........................... 995,4,1.....................updated\n",
            "  steps_per_print ................. 2...........................updated\n",
            "  synchronize_each_layer .......... True........................updated\n",
            "  tensorboard_dir ................. gpt-neox/tensorboard........updated\n",
            "  text_gen_type ................... unconditional...............updated\n",
            "  tokenizer_type .................. HFTokenizer.................updated\n",
            "  train_batch_size ................ 1024........................updated\n",
            "  train_iters ..................... 150000......................updated\n",
            "  train_micro_batch_size_per_gpu .. 16..........................updated\n",
            "  user_script ..................... gpt-neox/generate.py........updated\n",
            "  vocab_file ...................... gpt-neox/20B_checkpoints/20B_tokenizer.jsonupdated\n",
            "  wandb_group ..................... 6BkVvdvgYqjsDyueY5nNP3_1xqv5uwnupdated\n",
            "  zero_allgather_bucket_size ...... 1260000000..................updated\n",
            "  zero_contiguous_gradients ....... True........................updated\n",
            "  zero_optimization ............... {'stage': 1, 'allgather_partitions': True, 'allgather_bucket_size': 1260000000, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 1260000000, 'contiguous_gradients': True, 'cpu_offload': False}updated\n",
            "  zero_reduce_bucket_size ......... 1260000000..................updated\n",
            "  zero_reduce_scatter ............. True........................updated\n",
            "  zero_stage ...................... 1...........................updated\n",
            "  activation ...................... gelu........................default\n",
            "  adlr_autoresume ................. False.......................default\n",
            "  adlr_autoresume_interval ........ 1000........................default\n",
            "  amp ............................. None........................default\n",
            "  apply_query_key_layer_scaling ... False.......................default\n",
            "  attention_softmax_in_fp32 ....... False.......................default\n",
            "  bias_dropout_fusion ............. False.......................default\n",
            "  char_level_ppl .................. False.......................default\n",
            "  checkpoint_in_cpu ............... False.......................default\n",
            "  checkpoint_num_layers ........... 1...........................default\n",
            "  checkpoint_validation_with_forward_pass  False................default\n",
            "  contiguous_checkpointing ........ False.......................default\n",
            "  deepscale ....................... False.......................default\n",
            "  deepscale_config ................ None........................default\n",
            "  deepspeed ....................... True........................default\n",
            "  deepspeed_activation_checkpointing  True......................default\n",
            "  deepspeed_mpi ................... False.......................default\n",
            "  detect_nvlink_pairs ............. False.......................default\n",
            "  distributed_backend ............. nccl........................default\n",
            "  do_test ......................... None........................default\n",
            "  do_train ........................ None........................default\n",
            "  do_valid ........................ None........................default\n",
            "  dump_state ...................... False.......................default\n",
            "  eod_mask_loss ................... False.......................default\n",
            "  eval_interval ................... 1000........................default\n",
            "  eval_results_prefix ............. ............................default\n",
            "  eval_tasks ...................... None........................default\n",
            "  exclude ......................... None........................default\n",
            "  exit_interval ................... None........................default\n",
            "  finetune ........................ False.......................default\n",
            "  flops_profiler .................. None........................default\n",
            "  fp16_lm_cross_entropy ........... False.......................default\n",
            "  fp32_allreduce .................. False.......................default\n",
            "  git_hash ........................ None........................default\n",
            "  gmlp_attn_dim ................... 64..........................default\n",
            "  gradient_noise_scale_cpu_offload  False.......................default\n",
            "  gradient_noise_scale_n_batches .. 5...........................default\n",
            "  gradient_predivide_factor ....... 1.0.........................default\n",
            "  hostfile ........................ None........................default\n",
            "  hysteresis ...................... 2...........................default\n",
            "  include ......................... None........................default\n",
            "  init_method_std ................. 0.02........................default\n",
            "  iteration ....................... None........................default\n",
            "  keep_last_n_checkpoints ......... None........................default\n",
            "  launcher ........................ pdsh........................default\n",
            "  layernorm_epsilon ............... 1e-05.......................default\n",
            "  lazy_mpu_init ................... False.......................default\n",
            "  local_rank ...................... None........................default\n",
            "  log_grad_norm ................... False.......................default\n",
            "  log_grad_pct_zeros .............. False.......................default\n",
            "  log_gradient_noise_scale ........ False.......................default\n",
            "  log_optimizer_states ............ False.......................default\n",
            "  log_param_norm .................. False.......................default\n",
            "  loss_scale ...................... None........................default\n",
            "  loss_scale_window ............... 1000.0......................default\n",
            "  make_vocab_size_divisible_by .... 128.........................default\n",
            "  master_addr ..................... None........................default\n",
            "  master_port ..................... 29500.......................default\n",
            "  maximum_tokens .................. 64..........................default\n",
            "  merge_file ...................... None........................default\n",
            "  min_scale ....................... 1.0.........................default\n",
            "  mmap_warmup ..................... False.......................default\n",
            "  model_parallel_size ............. 1...........................default\n",
            "  no_load_optim ................... False.......................default\n",
            "  no_load_rng ..................... False.......................default\n",
            "  no_save_optim ................... False.......................default\n",
            "  no_save_rng ..................... False.......................default\n",
            "  norm ............................ layernorm...................default\n",
            "  num_gpus ........................ None........................default\n",
            "  num_nodes ....................... -1..........................default\n",
            "  num_samples ..................... 1...........................default\n",
            "  num_unique_layers ............... None........................default\n",
            "  num_workers ..................... 2...........................default\n",
            "  onnx_safe ....................... False.......................default\n",
            "  opt_pos_emb_offset .............. 0...........................default\n",
            "  override_lr_scheduler ........... False.......................default\n",
            "  padded_vocab_size ............... None........................default\n",
            "  param_sharing_style ............. grouped.....................default\n",
            "  partition_activations ........... False.......................default\n",
            "  pipe_partition_method ........... type:transformer|mlp........default\n",
            "  prescale_gradients .............. False.......................default\n",
            "  profile_backward ................ False.......................default\n",
            "  rank ............................ None........................default\n",
            "  recompute ....................... False.......................default\n",
            "  rms_norm_epsilon ................ 1e-08.......................default\n",
            "  rotary_emb_base ................. 10000.......................default\n",
            "  rpe_max_distance ................ 128.........................default\n",
            "  rpe_num_buckets ................. 32..........................default\n",
            "  sample_input_file ............... None........................default\n",
            "  sample_output_file .............. samples.txt.................default\n",
            "  scaled_masked_softmax_fusion .... False.......................default\n",
            "  scalenorm_epsilon ............... 1e-08.......................default\n",
            "  scheduler ....................... None........................default\n",
            "  seed ............................ 1234........................default\n",
            "  short_seq_prob .................. 0.1.........................default\n",
            "  soft_prompt_tuning .............. None........................default\n",
            "  sparse_gradients ................ False.......................default\n",
            "  temperature ..................... 0.0.........................default\n",
            "  test_data_paths ................. None........................default\n",
            "  test_data_weights ............... None........................default\n",
            "  top_k ........................... 0...........................default\n",
            "  top_p ........................... 0.0.........................default\n",
            "  train_data_paths ................ None........................default\n",
            "  train_data_weights .............. None........................default\n",
            "  use_bnb_optimizer ............... False.......................default\n",
            "  use_checkpoint_lr_scheduler ..... False.......................default\n",
            "  use_cpu_initialization .......... False.......................default\n",
            "  use_wandb ....................... None........................default\n",
            "  valid_data_paths ................ None........................default\n",
            "  valid_data_weights .............. None........................default\n",
            "  wall_clock_breakdown ............ False.......................default\n",
            "  wandb_host ...................... https://api.wandb.ai........default\n",
            "  wandb_init_all_ranks ............ False.......................default\n",
            "  wandb_project ................... neox........................default\n",
            "  wandb_team ...................... None........................default\n",
            "  warmup .......................... 0.01........................default\n",
            "  weight_by_num_documents ......... False.......................default\n",
            "  weight_decay .................... 0.01........................default\n",
            "  weighted_sampler_alpha .......... 0.3.........................default\n",
            "  world_size ...................... None........................default\n",
            "  zero_allow_untested_optimizer ... False.......................default\n",
            "---------------- end of arguments ----------------\n",
            "[2022-07-28 06:53:52,732] [WARNING] [runner.py:126:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2022-07-28 06:53:52,732] [INFO] [runner.py:366:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 gpt-neox/generate.py --deepspeed_config {\"train_batch_size\": 1024, \"train_micro_batch_size_per_gpu\": 16, \"gradient_accumulation_steps\": 64, \"optimizer\": {\"type\": \"Adam\", \"params\": {\"lr\": 9.7e-05, \"betas\": [0.9, 0.95], \"eps\": 1e-08}}, \"fp16\": {\"fp16\": true, \"enabled\": true, \"loss_scale\": 0, \"loss_scale_window\": 1000, \"initial_scale_power\": 12, \"hysteresis\": 2, \"min_loss_scale\": 1}, \"gradient_clipping\": 1.0, \"zero_optimization\": {\"stage\": 1, \"allgather_partitions\": true, \"allgather_bucket_size\": 1260000000, \"overlap_comm\": true, \"reduce_scatter\": true, \"reduce_bucket_size\": 1260000000, \"contiguous_gradients\": true, \"cpu_offload\": false}, \"steps_per_print\": 2} --megatron_config {\"train_batch_size\": 1024, \"train_micro_batch_size_per_gpu\": 16, \"gradient_accumulation_steps\": 64, \"optimizer\": {\"type\": \"Adam\", \"params\": {\"lr\": 9.7e-05, \"betas\": [0.9, 0.95], \"eps\": 1e-08}}, \"fp16\": {\"fp16\": true, \"enabled\": true, \"loss_scale\": 0, \"loss_scale_window\": 1000, \"initial_scale_power\": 12, \"hysteresis\": 2, \"min_loss_scale\": 1}, \"gradient_clipping\": 1.0, \"zero_optimization\": {\"stage\": 1, \"allgather_partitions\": true, \"allgather_bucket_size\": 1260000000, \"overlap_comm\": true, \"reduce_scatter\": true, \"reduce_bucket_size\": 1260000000, \"contiguous_gradients\": true, \"cpu_offload\": false}, \"steps_per_print\": 2, \"precision\": \"fp16\", \"num_layers\": 44, \"hidden_size\": 6144, \"num_attention_heads\": 64, \"seq_length\": 2048, \"max_position_embeddings\": 2048, \"pos_emb\": \"rotary\", \"no_weight_tying\": true, \"attention_config\": [\"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\"], \"sparsity_config\": {}, \"scaled_upper_triang_masked_softmax_fusion\": true, \"bias_gelu_fusion\": true, \"rotary_pct\": 0.25, \"init_method\": \"small_init\", \"output_layer_init_method\": \"wang_init\", \"gpt_j_residual\": true, \"output_layer_parallelism\": \"column\", \"lr_decay_style\": \"cosine\", \"lr_decay_iters\": 150000, \"min_lr\": 9.7e-06, \"optimizer_type\": \"Adam\", \"zero_stage\": 1, \"zero_reduce_scatter\": true, \"zero_contiguous_gradients\": true, \"zero_reduce_bucket_size\": 1260000000, \"zero_allgather_bucket_size\": 1260000000, \"lr\": 9.7e-05, \"tokenizer_type\": \"HFTokenizer\", \"data_path\": \"./data/pile_20B_tokenizer/pile_20B_tokenizer_text_document\", \"data_impl\": \"mmap\", \"save\": \"gpt-neox/20B_checkpoints\", \"config_files\": {\"20B.yml\": \"# DISCLAIMER: This is the configuration file for the GPT-NeoX-20B model as it was trained on 96x 40GB A100\\n# GPUs. Depending on your system configuration, you may need to change some parameters in order to fit\\n# the model in memory.\\n\\n{\\n  # Tokenizer /  checkpoint settings - you will need to change these to the location you have them saved in\\n  \\\"vocab-file\\\": \\\"gpt-neox/20B_checkpoints/20B_tokenizer.json\\\",\\n  \\\"save\\\": \\\"gpt-neox/20B_checkpoints\\\",\\n  \\\"load\\\": \\\"gpt-neox/20B_checkpoints\\\",\\n\\n  # If finetuning, edit the following to the location of your finetuning dataset:\\n  \\\"data-path\\\": \\\"./data/pile_20B_tokenizer/pile_20B_tokenizer_text_document\\\",\\n\\n  # parallelism settings ( you will want to change these based on your cluster setup, ideally scheduling pipeline stages\\n  # across the node boundaries )\\n  \\\"pipe-parallel-size\\\": 1,\\n  \\\"model-parallel-size\\\": 1,\\n\\n  # model settings\\n  \\\"num-layers\\\": 44,\\n  \\\"hidden-size\\\": 6144,\\n  \\\"num-attention-heads\\\": 64,\\n  \\\"seq-length\\\": 2048,\\n  \\\"max-position-embeddings\\\": 2048,\\n  \\\"norm\\\": \\\"layernorm\\\",\\n  \\\"pos-emb\\\": \\\"rotary\\\",\\n  \\\"rotary_pct\\\": 0.25,\\n  \\\"no-weight-tying\\\": true,\\n  \\\"gpt_j_residual\\\": true,\\n  \\\"output_layer_parallelism\\\": \\\"column\\\",\\n  \\\"scaled-upper-triang-masked-softmax-fusion\\\": true,\\n  \\\"bias-gelu-fusion\\\": true,\\n\\n  # init methods\\n  \\\"init_method\\\": \\\"small_init\\\",\\n  \\\"output_layer_init_method\\\": \\\"wang_init\\\",\\n\\n  # optimizer settings\\n  \\\"optimizer\\\": {\\n    \\\"type\\\": \\\"Adam\\\",\\n    \\\"params\\\": {\\n      \\\"lr\\\": 0.97e-4,\\n      \\\"betas\\\": [0.9, 0.95],\\n      \\\"eps\\\": 1.0e-8,\\n      }\\n      },\\n\\n  \\\"min_lr\\\": 0.97e-5,\\n  \\\"zero_optimization\\\": {\\n  \\\"stage\\\": 1,\\n  \\\"allgather_partitions\\\": True,\\n  \\\"allgather_bucket_size\\\": 1260000000,\\n  \\\"overlap_comm\\\": True,\\n  \\\"reduce_scatter\\\": True,\\n  \\\"reduce_bucket_size\\\": 1260000000,\\n  \\\"contiguous_gradients\\\": True,\\n  \\\"cpu_offload\\\": False\\n  },\\n\\n  # batch / data settings (assuming 96 GPUs)\\n  \\\"train_micro_batch_size_per_gpu\\\": 16,\\n  \\\"gradient_accumulation_steps\\\": 64,\\n  \\\"data-impl\\\": \\\"mmap\\\",\\n  \\\"split\\\": \\\"995,4,1\\\",\\n\\n  # activation checkpointing\\n  \\\"checkpoint-activations\\\": true,\\n  \\\"checkpoint-num-layers\\\": 1,\\n  \\\"partition-activations\\\": false,\\n  \\\"synchronize-each-layer\\\": true,\\n\\n  # regularization\\n  \\\"gradient_clipping\\\": 1.0,\\n  \\\"weight-decay\\\": 0.01,\\n  \\\"hidden-dropout\\\": 0,\\n  \\\"attention-dropout\\\": 0,\\n\\n  # precision settings\\n  \\\"fp16\\\": {\\n    \\\"fp16\\\": true,\\n    \\\"enabled\\\": true,\\n    \\\"loss_scale\\\": 0,\\n    \\\"loss_scale_window\\\": 1000,\\n    \\\"initial_scale_power\\\": 12,\\n    \\\"hysteresis\\\": 2,\\n    \\\"min_loss_scale\\\": 1\\n    },\\n\\n  # misc. training settings\\n  \\\"train-iters\\\": 150000,\\n  \\\"lr-decay-iters\\\": 150000,\\n\\n  \\\"distributed-backend\\\": \\\"nccl\\\",\\n  \\\"lr-decay-style\\\": \\\"cosine\\\",\\n  \\\"warmup\\\": 0.01,\\n  \\\"save-interval\\\": 500,\\n  \\\"eval-interval\\\": 1000,\\n  \\\"eval-iters\\\": 10,\\n\\n  # logging\\n  \\\"log-interval\\\": 2,\\n  \\\"steps_per_print\\\": 2,\\n  \\\"wall_clock_breakdown\\\": false,\\n\\n  ### NEW DATA: ####\\n  \\\"tokenizer_type\\\": \\\"HFTokenizer\\\",\\n  \\\"tensorboard-dir\\\": \\\"gpt-neox/tensorboard\\\",\\n  \\\"log-dir\\\": \\\"gpt-neox/logs\\\",\\n\\n}\\n\"}, \"load\": \"gpt-neox/20B_checkpoints\", \"save_interval\": 500, \"batch_size\": 16, \"train_iters\": 150000, \"eval_iters\": 10, \"split\": \"995,4,1\", \"vocab_file\": \"gpt-neox/20B_checkpoints/20B_tokenizer.json\", \"attention_dropout\": 0, \"hidden_dropout\": 0, \"checkpoint_activations\": true, \"synchronize_each_layer\": true, \"gas\": 64, \"clip_grad\": 1.0, \"dynamic_loss_scale\": true, \"pipe_parallel_size\": 1, \"is_pipe_parallel\": true, \"wandb_group\": \"6BkVvdvgYqjsDyueY5nNP3_1xqv5uwn\", \"log_dir\": \"gpt-neox/logs\", \"tensorboard_dir\": \"gpt-neox/tensorboard\", \"log_interval\": 2, \"text_gen_type\": \"unconditional\", \"user_script\": \"gpt-neox/generate.py\", \"global_num_gpus\": 1}\n",
            "[2022-07-28 06:53:53,458] [INFO] [launch.py:75:main] 0 NCCL_VERSION 2.7.8\n",
            "[2022-07-28 06:53:53,459] [INFO] [launch.py:82:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2022-07-28 06:53:53,459] [INFO] [launch.py:91:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2022-07-28 06:53:53,459] [INFO] [launch.py:103:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2022-07-28 06:53:53,459] [INFO] [launch.py:104:main] dist_world_size=1\n",
            "[2022-07-28 06:53:53,459] [INFO] [launch.py:113:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 1 \n",
            "> building HFTokenizer tokenizer ...\n",
            " > padded vocab (size: 50277) with 27 dummy tokens (new size: 50304)\n",
            "> initializing torch distributed ...\n",
            "[2022-07-28 06:53:57,902] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
            "> initializing model parallel with size 1\n",
            "MPU DP: [0]\n",
            "MPU PP: [0]\n",
            "MPU MP: [0]\n",
            "> setting random seeds to 1234 ...\n",
            "[2022-07-28 06:53:57,905] [INFO] [checkpointing.py:231:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n",
            "make: Entering directory '/content/gpt-neox/megatron/data'\n",
            "make: Nothing to be done for 'default'.\n",
            "make: Leaving directory '/content/gpt-neox/megatron/data'\n",
            "building GPT2 model ...\n",
            "SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None\n",
            "Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0}\n",
            "[2022-07-28 06:53:57,978] [INFO] [module.py:363:_partition_layers] Partitioning pipeline stages with method type:transformer|mlp\n",
            "stage=0 layers=49\n",
            "     0: EmbeddingPipe\n",
            "     1: _pre_transformer_block\n",
            "     2: ParallelTransformerLayerPipe\n",
            "     3: ParallelTransformerLayerPipe\n",
            "     4: ParallelTransformerLayerPipe\n",
            "     5: ParallelTransformerLayerPipe\n",
            "     6: ParallelTransformerLayerPipe\n",
            "     7: ParallelTransformerLayerPipe\n",
            "     8: ParallelTransformerLayerPipe\n",
            "     9: ParallelTransformerLayerPipe\n",
            "    10: ParallelTransformerLayerPipe\n",
            "    11: ParallelTransformerLayerPipe\n",
            "    12: ParallelTransformerLayerPipe\n",
            "    13: ParallelTransformerLayerPipe\n",
            "    14: ParallelTransformerLayerPipe\n",
            "    15: ParallelTransformerLayerPipe\n",
            "    16: ParallelTransformerLayerPipe\n",
            "    17: ParallelTransformerLayerPipe\n",
            "    18: ParallelTransformerLayerPipe\n",
            "    19: ParallelTransformerLayerPipe\n",
            "    20: ParallelTransformerLayerPipe\n",
            "    21: ParallelTransformerLayerPipe\n",
            "    22: ParallelTransformerLayerPipe\n",
            "    23: ParallelTransformerLayerPipe\n",
            "    24: ParallelTransformerLayerPipe\n",
            "    25: ParallelTransformerLayerPipe\n",
            "    26: ParallelTransformerLayerPipe\n",
            "    27: ParallelTransformerLayerPipe\n",
            "    28: ParallelTransformerLayerPipe\n",
            "    29: ParallelTransformerLayerPipe\n",
            "    30: ParallelTransformerLayerPipe\n",
            "    31: ParallelTransformerLayerPipe\n",
            "    32: ParallelTransformerLayerPipe\n",
            "    33: ParallelTransformerLayerPipe\n",
            "    34: ParallelTransformerLayerPipe\n",
            "    35: ParallelTransformerLayerPipe\n",
            "    36: ParallelTransformerLayerPipe\n",
            "    37: ParallelTransformerLayerPipe\n",
            "    38: ParallelTransformerLayerPipe\n",
            "    39: ParallelTransformerLayerPipe\n",
            "    40: ParallelTransformerLayerPipe\n",
            "    41: ParallelTransformerLayerPipe\n",
            "    42: ParallelTransformerLayerPipe\n",
            "    43: ParallelTransformerLayerPipe\n",
            "    44: ParallelTransformerLayerPipe\n",
            "    45: ParallelTransformerLayerPipe\n",
            "    46: _post_transformer_block\n",
            "    47: NormPipe\n",
            "    48: ParallelLinearPipe\n",
            "  loss: partial\n",
            "Traceback (most recent call last):\n",
            "  File \"gpt-neox/generate.py\", line 88, in <module>\n",
            "    main()\n",
            "  File \"gpt-neox/generate.py\", line 32, in main\n",
            "    model, neox_args = setup_for_inference_or_eval(use_cache=True)\n",
            "  File \"/content/gpt-neox/megatron/utils.py\", line 436, in setup_for_inference_or_eval\n",
            "    iteration=neox_args.iteration,\n",
            "  File \"/content/gpt-neox/megatron/training.py\", line 402, in setup_model_and_optimizer\n",
            "    model = get_model(neox_args=neox_args, use_cache=use_cache)\n",
            "  File \"/content/gpt-neox/megatron/training.py\", line 241, in get_model\n",
            "    use_cache=use_cache,\n",
            "  File \"/content/gpt-neox/megatron/model/gpt2_model.py\", line 131, in __init__\n",
            "    checkpointable_layers=[\"GMLPBlock\", \"ParallelTransformerLayerPipe\"],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deepspeed/runtime/pipe/module.py\", line 195, in __init__\n",
            "    self._build()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deepspeed/runtime/pipe/module.py\", line 246, in _build\n",
            "    module = layer.build()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deepspeed/runtime/pipe/module.py\", line 69, in build\n",
            "    return self.typename(*self.module_args, **self.module_kwargs)\n",
            "  File \"/content/gpt-neox/megatron/model/transformer.py\", line 572, in __init__\n",
            "    parallel_output=self.gpt_j_residual,\n",
            "  File \"/content/gpt-neox/megatron/model/transformer.py\", line 113, in __init__\n",
            "    parallel_output=parallel_output,\n",
            "  File \"/content/gpt-neox/megatron/mpu/layers.py\", line 553, in __init__\n",
            "    dtype=neox_args.params_dtype,\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 288.00 MiB (GPU 0; 14.76 GiB total capacity; 13.80 GiB already allocated; 193.75 MiB free; 13.80 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "Killing subprocess 2599\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deepspeed/launcher/launch.py\", line 179, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deepspeed/launcher/launch.py\", line 169, in main\n",
            "    sigkill_handler(signal.SIGTERM, None)  # not coming back\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deepspeed/launcher/launch.py\", line 147, in sigkill_handler\n",
            "    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-u', 'gpt-neox/generate.py', '--local_rank=0', '--deepspeed_config', '{\"train_batch_size\": 1024, \"train_micro_batch_size_per_gpu\": 16, \"gradient_accumulation_steps\": 64, \"optimizer\": {\"type\": \"Adam\", \"params\": {\"lr\": 9.7e-05, \"betas\": [0.9, 0.95], \"eps\": 1e-08}}, \"fp16\": {\"fp16\": true, \"enabled\": true, \"loss_scale\": 0, \"loss_scale_window\": 1000, \"initial_scale_power\": 12, \"hysteresis\": 2, \"min_loss_scale\": 1}, \"gradient_clipping\": 1.0, \"zero_optimization\": {\"stage\": 1, \"allgather_partitions\": true, \"allgather_bucket_size\": 1260000000, \"overlap_comm\": true, \"reduce_scatter\": true, \"reduce_bucket_size\": 1260000000, \"contiguous_gradients\": true, \"cpu_offload\": false}, \"steps_per_print\": 2}', '--megatron_config', '{\"train_batch_size\": 1024, \"train_micro_batch_size_per_gpu\": 16, \"gradient_accumulation_steps\": 64, \"optimizer\": {\"type\": \"Adam\", \"params\": {\"lr\": 9.7e-05, \"betas\": [0.9, 0.95], \"eps\": 1e-08}}, \"fp16\": {\"fp16\": true, \"enabled\": true, \"loss_scale\": 0, \"loss_scale_window\": 1000, \"initial_scale_power\": 12, \"hysteresis\": 2, \"min_loss_scale\": 1}, \"gradient_clipping\": 1.0, \"zero_optimization\": {\"stage\": 1, \"allgather_partitions\": true, \"allgather_bucket_size\": 1260000000, \"overlap_comm\": true, \"reduce_scatter\": true, \"reduce_bucket_size\": 1260000000, \"contiguous_gradients\": true, \"cpu_offload\": false}, \"steps_per_print\": 2, \"precision\": \"fp16\", \"num_layers\": 44, \"hidden_size\": 6144, \"num_attention_heads\": 64, \"seq_length\": 2048, \"max_position_embeddings\": 2048, \"pos_emb\": \"rotary\", \"no_weight_tying\": true, \"attention_config\": [\"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\"], \"sparsity_config\": {}, \"scaled_upper_triang_masked_softmax_fusion\": true, \"bias_gelu_fusion\": true, \"rotary_pct\": 0.25, \"init_method\": \"small_init\", \"output_layer_init_method\": \"wang_init\", \"gpt_j_residual\": true, \"output_layer_parallelism\": \"column\", \"lr_decay_style\": \"cosine\", \"lr_decay_iters\": 150000, \"min_lr\": 9.7e-06, \"optimizer_type\": \"Adam\", \"zero_stage\": 1, \"zero_reduce_scatter\": true, \"zero_contiguous_gradients\": true, \"zero_reduce_bucket_size\": 1260000000, \"zero_allgather_bucket_size\": 1260000000, \"lr\": 9.7e-05, \"tokenizer_type\": \"HFTokenizer\", \"data_path\": \"./data/pile_20B_tokenizer/pile_20B_tokenizer_text_document\", \"data_impl\": \"mmap\", \"save\": \"gpt-neox/20B_checkpoints\", \"config_files\": {\"20B.yml\": \"# DISCLAIMER: This is the configuration file for the GPT-NeoX-20B model as it was trained on 96x 40GB A100\\\\n# GPUs. Depending on your system configuration, you may need to change some parameters in order to fit\\\\n# the model in memory.\\\\n\\\\n{\\\\n  # Tokenizer /  checkpoint settings - you will need to change these to the location you have them saved in\\\\n  \\\\\"vocab-file\\\\\": \\\\\"gpt-neox/20B_checkpoints/20B_tokenizer.json\\\\\",\\\\n  \\\\\"save\\\\\": \\\\\"gpt-neox/20B_checkpoints\\\\\",\\\\n  \\\\\"load\\\\\": \\\\\"gpt-neox/20B_checkpoints\\\\\",\\\\n\\\\n  # If finetuning, edit the following to the location of your finetuning dataset:\\\\n  \\\\\"data-path\\\\\": \\\\\"./data/pile_20B_tokenizer/pile_20B_tokenizer_text_document\\\\\",\\\\n\\\\n  # parallelism settings ( you will want to change these based on your cluster setup, ideally scheduling pipeline stages\\\\n  # across the node boundaries )\\\\n  \\\\\"pipe-parallel-size\\\\\": 1,\\\\n  \\\\\"model-parallel-size\\\\\": 1,\\\\n\\\\n  # model settings\\\\n  \\\\\"num-layers\\\\\": 44,\\\\n  \\\\\"hidden-size\\\\\": 6144,\\\\n  \\\\\"num-attention-heads\\\\\": 64,\\\\n  \\\\\"seq-length\\\\\": 2048,\\\\n  \\\\\"max-position-embeddings\\\\\": 2048,\\\\n  \\\\\"norm\\\\\": \\\\\"layernorm\\\\\",\\\\n  \\\\\"pos-emb\\\\\": \\\\\"rotary\\\\\",\\\\n  \\\\\"rotary_pct\\\\\": 0.25,\\\\n  \\\\\"no-weight-tying\\\\\": true,\\\\n  \\\\\"gpt_j_residual\\\\\": true,\\\\n  \\\\\"output_layer_parallelism\\\\\": \\\\\"column\\\\\",\\\\n  \\\\\"scaled-upper-triang-masked-softmax-fusion\\\\\": true,\\\\n  \\\\\"bias-gelu-fusion\\\\\": true,\\\\n\\\\n  # init methods\\\\n  \\\\\"init_method\\\\\": \\\\\"small_init\\\\\",\\\\n  \\\\\"output_layer_init_method\\\\\": \\\\\"wang_init\\\\\",\\\\n\\\\n  # optimizer settings\\\\n  \\\\\"optimizer\\\\\": {\\\\n    \\\\\"type\\\\\": \\\\\"Adam\\\\\",\\\\n    \\\\\"params\\\\\": {\\\\n      \\\\\"lr\\\\\": 0.97e-4,\\\\n      \\\\\"betas\\\\\": [0.9, 0.95],\\\\n      \\\\\"eps\\\\\": 1.0e-8,\\\\n      }\\\\n      },\\\\n\\\\n  \\\\\"min_lr\\\\\": 0.97e-5,\\\\n  \\\\\"zero_optimization\\\\\": {\\\\n  \\\\\"stage\\\\\": 1,\\\\n  \\\\\"allgather_partitions\\\\\": True,\\\\n  \\\\\"allgather_bucket_size\\\\\": 1260000000,\\\\n  \\\\\"overlap_comm\\\\\": True,\\\\n  \\\\\"reduce_scatter\\\\\": True,\\\\n  \\\\\"reduce_bucket_size\\\\\": 1260000000,\\\\n  \\\\\"contiguous_gradients\\\\\": True,\\\\n  \\\\\"cpu_offload\\\\\": False\\\\n  },\\\\n\\\\n  # batch / data settings (assuming 96 GPUs)\\\\n  \\\\\"train_micro_batch_size_per_gpu\\\\\": 16,\\\\n  \\\\\"gradient_accumulation_steps\\\\\": 64,\\\\n  \\\\\"data-impl\\\\\": \\\\\"mmap\\\\\",\\\\n  \\\\\"split\\\\\": \\\\\"995,4,1\\\\\",\\\\n\\\\n  # activation checkpointing\\\\n  \\\\\"checkpoint-activations\\\\\": true,\\\\n  \\\\\"checkpoint-num-layers\\\\\": 1,\\\\n  \\\\\"partition-activations\\\\\": false,\\\\n  \\\\\"synchronize-each-layer\\\\\": true,\\\\n\\\\n  # regularization\\\\n  \\\\\"gradient_clipping\\\\\": 1.0,\\\\n  \\\\\"weight-decay\\\\\": 0.01,\\\\n  \\\\\"hidden-dropout\\\\\": 0,\\\\n  \\\\\"attention-dropout\\\\\": 0,\\\\n\\\\n  # precision settings\\\\n  \\\\\"fp16\\\\\": {\\\\n    \\\\\"fp16\\\\\": true,\\\\n    \\\\\"enabled\\\\\": true,\\\\n    \\\\\"loss_scale\\\\\": 0,\\\\n    \\\\\"loss_scale_window\\\\\": 1000,\\\\n    \\\\\"initial_scale_power\\\\\": 12,\\\\n    \\\\\"hysteresis\\\\\": 2,\\\\n    \\\\\"min_loss_scale\\\\\": 1\\\\n    },\\\\n\\\\n  # misc. training settings\\\\n  \\\\\"train-iters\\\\\": 150000,\\\\n  \\\\\"lr-decay-iters\\\\\": 150000,\\\\n\\\\n  \\\\\"distributed-backend\\\\\": \\\\\"nccl\\\\\",\\\\n  \\\\\"lr-decay-style\\\\\": \\\\\"cosine\\\\\",\\\\n  \\\\\"warmup\\\\\": 0.01,\\\\n  \\\\\"save-interval\\\\\": 500,\\\\n  \\\\\"eval-interval\\\\\": 1000,\\\\n  \\\\\"eval-iters\\\\\": 10,\\\\n\\\\n  # logging\\\\n  \\\\\"log-interval\\\\\": 2,\\\\n  \\\\\"steps_per_print\\\\\": 2,\\\\n  \\\\\"wall_clock_breakdown\\\\\": false,\\\\n\\\\n  ### NEW DATA: ####\\\\n  \\\\\"tokenizer_type\\\\\": \\\\\"HFTokenizer\\\\\",\\\\n  \\\\\"tensorboard-dir\\\\\": \\\\\"gpt-neox/tensorboard\\\\\",\\\\n  \\\\\"log-dir\\\\\": \\\\\"gpt-neox/logs\\\\\",\\\\n\\\\n}\\\\n\"}, \"load\": \"gpt-neox/20B_checkpoints\", \"save_interval\": 500, \"batch_size\": 16, \"train_iters\": 150000, \"eval_iters\": 10, \"split\": \"995,4,1\", \"vocab_file\": \"gpt-neox/20B_checkpoints/20B_tokenizer.json\", \"attention_dropout\": 0, \"hidden_dropout\": 0, \"checkpoint_activations\": true, \"synchronize_each_layer\": true, \"gas\": 64, \"clip_grad\": 1.0, \"dynamic_loss_scale\": true, \"pipe_parallel_size\": 1, \"is_pipe_parallel\": true, \"wandb_group\": \"6BkVvdvgYqjsDyueY5nNP3_1xqv5uwn\", \"log_dir\": \"gpt-neox/logs\", \"tensorboard_dir\": \"gpt-neox/tensorboard\", \"log_interval\": 2, \"text_gen_type\": \"unconditional\", \"user_script\": \"gpt-neox/generate.py\", \"global_num_gpus\": 1}']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "X6l3DOL-kjCa"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}